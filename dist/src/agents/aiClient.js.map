{"version":3,"file":"aiClient.js","sourceRoot":"","sources":["../../../src/agents/aiClient.ts"],"names":[],"mappings":"AAAA,OAAO,MAAM,MAAM,QAAQ,CAAC;AAC5B,OAAO,EAAE,MAAM,EAAE,MAAM,cAAc,CAAC;AACtC,OAAO,EAAE,YAAY,EAAE,MAAM,EAAE,UAAU,EAAE,MAAM,SAAS,CAAC;AA6C3D,mBAAmB;AACnB,MAAM,MAAM,GAAG,YAAY,CAAC;IAC1B,MAAM,EAAE,MAAM,CAAC,OAAO,CACpB,MAAM,CAAC,SAAS,EAAE,EAClB,MAAM,CAAC,IAAI,EAAE,CACd;IACD,UAAU,EAAE;QACV,IAAI,UAAU,CAAC,OAAO,EAAE;QACxB,IAAI,UAAU,CAAC,IAAI,CAAC,EAAE,QAAQ,EAAE,WAAW,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC;QAC9D,IAAI,UAAU,CAAC,IAAI,CAAC,EAAE,QAAQ,EAAE,eAAe,EAAE,CAAC;KACnD;CACF,CAAC,CAAC;AAEH;;GAEG;AACH,MAAM,OAAO,OAAQ,SAAQ,KAAK;IACa;IAA7C,YAAY,OAAe,EAAkB,OAAiB;QAC5D,KAAK,CAAC,OAAO,CAAC,CAAC;QAD4B,YAAO,GAAP,OAAO,CAAU;QAE5D,IAAI,CAAC,IAAI,GAAG,SAAS,CAAC;IACxB,CAAC;CACF;AAED;;GAEG;AACH,MAAM,OAAO,QAAQ;IACF,MAAM,CAAS;IACf,MAAM,CAA2B;IAElD;;;;;OAKG;IACH,YACE,SAAiB,MAAM,CAAC,cAAc,EACtC,SAAyB,EAAE;QAE3B,IAAI,CAAC,MAAM,EAAE,IAAI,EAAE,EAAE,CAAC;YACpB,MAAM,IAAI,OAAO,CAAC,4BAA4B,CAAC,CAAC;QAClD,CAAC;QAED,IAAI,CAAC,MAAM,GAAG,IAAI,MAAM,CAAC,EAAE,MAAM,EAAE,CAAC,CAAC;QACrC,IAAI,CAAC,MAAM,GAAG;YACZ,KAAK,EAAE,MAAM,CAAC,KAAK,IAAI,OAAO;YAC9B,WAAW,EAAE,MAAM,CAAC,WAAW,IAAI,GAAG;YACtC,UAAU,EAAE,MAAM,CAAC,UAAU,IAAI,CAAC;YAClC,UAAU,EAAE,MAAM,CAAC,UAAU,IAAI,IAAI;YACrC,YAAY,EAAE,MAAM,CAAC,YAAY,IAAI,IAAI,CAAC,sBAAsB,EAAE;YAClE,OAAO,EAAE,MAAM,CAAC,OAAO,IAAI,KAAK;SACjC,CAAC;QAEF,MAAM,CAAC,IAAI,CAAC,sBAAsB,EAAE;YAClC,KAAK,EAAE,IAAI,CAAC,MAAM,CAAC,KAAK;YACxB,WAAW,EAAE,IAAI,CAAC,MAAM,CAAC,WAAW;SACrC,CAAC,CAAC;IACL,CAAC;IAEO,sBAAsB;QAC5B,OAAO;;;;;;;;;;;;;;;;;;;;;;;;;;;;;4BA6BiB,CAAC;IAC3B,CAAC;IAED;;;;;;OAMG;IACH,KAAK,CAAC,GAAG,CAAC,MAAc,EAAE,SAAkC,EAAE;QAC5D,MAAM,SAAS,GAAG,IAAI,CAAC,GAAG,EAAE,CAAC;QAC7B,IAAI,UAAU,GAAG,CAAC,CAAC;QAEnB,IAAI,CAAC;YACH,IAAI,CAAC,MAAM,EAAE,IAAI,EAAE,EAAE,CAAC;gBACpB,MAAM,IAAI,OAAO,CAAC,wBAAwB,CAAC,CAAC;YAC9C,CAAC;YAED,MAAM,eAAe,GAAG,EAAE,GAAG,IAAI,CAAC,MAAM,EAAE,GAAG,MAAM,EAAE,CAAC;YACtD,IAAI,SAAS,GAAiB,IAAI,CAAC;YAEnC,KAAK,IAAI,OAAO,GAAG,CAAC,EAAE,OAAO,IAAI,eAAe,CAAC,UAAU,EAAE,OAAO,EAAE,EAAE,CAAC;gBACvE,IAAI,CAAC;oBACH,MAAM,UAAU,GAAG,MAAM,OAAO,CAAC,IAAI,CAAC;wBACpC,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;4BAClC,KAAK,EAAE,eAAe,CAAC,KAAK;4BAC5B,QAAQ,EAAE;gCACR;oCACE,IAAI,EAAE,QAAQ;oCACd,OAAO,EAAE,eAAe,CAAC,YAAY;iCACtC;gCACD,EAAE,IAAI,EAAE,MAAM,EAAE,OAAO,EAAE,MAAM,EAAE;6BAClC;4BACD,WAAW,EAAE,eAAe,CAAC,WAAW;4BACxC,UAAU,EAAE,IAAI;4BAChB,gBAAgB,EAAE,GAAG;4BACrB,iBAAiB,EAAE,GAAG;yBACvB,CAAC;wBACF,IAAI,OAAO,CAAC,CAAC,CAAC,EAAE,MAAM,EAAE,EAAE,CAAC,UAAU,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,IAAI,OAAO,CAAC,iBAAiB,CAAC,CAAC,EAAE,eAAe,CAAC,OAAO,CAAC,CAAC;qBAC9G,CAA+B,CAAC;oBAEjC,MAAM,OAAO,GAAG,UAAU,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,OAAO,EAAE,OAAO,CAAC;oBACxD,IAAI,CAAC,OAAO,EAAE,IAAI,EAAE,EAAE,CAAC;wBACrB,MAAM,IAAI,OAAO,CAAC,4BAA4B,CAAC,CAAC;oBAClD,CAAC;oBAED,MAAM,QAAQ,GAAG,IAAI,CAAC,GAAG,EAAE,GAAG,SAAS,CAAC;oBACxC,MAAM,CAAC,IAAI,CAAC,uBAAuB,EAAE;wBACnC,QAAQ;wBACR,KAAK,EAAE,eAAe,CAAC,KAAK;wBAC5B,MAAM,EAAE,UAAU,CAAC,KAAK,EAAE,YAAY;qBACvC,CAAC,CAAC;oBAEH,OAAO;wBACL,OAAO;wBACP,KAAK,EAAE,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC;4BACxB,YAAY,EAAE,UAAU,CAAC,KAAK,CAAC,aAAa;4BAC5C,gBAAgB,EAAE,UAAU,CAAC,KAAK,CAAC,iBAAiB;4BACpD,WAAW,EAAE,UAAU,CAAC,KAAK,CAAC,YAAY;yBAC3C,CAAC,CAAC,CAAC,SAAS;wBACb,QAAQ,EAAE;4BACR,SAAS,EAAE,IAAI,IAAI,EAAE,CAAC,WAAW,EAAE;4BACnC,KAAK,EAAE,eAAe,CAAC,KAAK;4BAC5B,QAAQ;4BACR,OAAO,EAAE,UAAU;yBACpB;qBACF,CAAC;gBACJ,CAAC;gBAAC,OAAO,KAAK,EAAE,CAAC;oBACf,UAAU,EAAE,CAAC;oBACb,SAAS,GAAG,KAAK,YAAY,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,IAAI,KAAK,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC;oBACtE,MAAM,CAAC,IAAI,CAAC,WAAW,OAAO,SAAS,EAAE;wBACvC,KAAK,EAAE,SAAS,CAAC,OAAO;wBACxB,OAAO;wBACP,UAAU;qBACX,CAAC,CAAC;oBAEH,IAAI,OAAO,GAAG,eAAe,CAAC,UAAU,EAAE,CAAC;wBACzC,MAAM,KAAK,GAAG,eAAe,CAAC,UAAU,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,OAAO,GAAG,CAAC,CAAC,CAAC;wBACpE,MAAM,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,sBAAsB;wBAC/C,SAAS;oBACX,CAAC;gBACH,CAAC;YACH,CAAC;YAED,MAAM,IAAI,OAAO,CACf,gBAAgB,eAAe,CAAC,UAAU,WAAW,EACrD,SAAS,EAAE,OAAO,CACnB,CAAC;QACJ,CAAC;QAAC,OAAO,KAAK,EAAE,CAAC;YACf,MAAM,UAAU,GAAG,KAAK,YAAY,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,IAAI,KAAK,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC;YAC7E,MAAM,CAAC,KAAK,CAAC,mBAAmB,EAAE;gBAChC,KAAK,EAAE,UAAU,CAAC,OAAO;gBACzB,QAAQ,EAAE,IAAI,CAAC,GAAG,EAAE,GAAG,SAAS;gBAChC,OAAO,EAAE,UAAU;aACpB,CAAC,CAAC;YACH,MAAM,IAAI,OAAO,CAAC,UAAU,CAAC,OAAO,EAAE;gBACpC,QAAQ,EAAE,IAAI,CAAC,GAAG,EAAE,GAAG,SAAS;gBAChC,OAAO,EAAE,UAAU;aACpB,CAAC,CAAC;QACL,CAAC;IACH,CAAC;IAEO,KAAK,CAAC,EAAU;QACtB,OAAO,IAAI,OAAO,CAAC,OAAO,CAAC,EAAE,CAAC,UAAU,CAAC,OAAO,EAAE,EAAE,CAAC,CAAC,CAAC;IACzD,CAAC;CACF;AAED;;;;;GAKG;AACH,MAAM,CAAC,MAAM,KAAK,GAAG,KAAK,EAAE,MAAc,EAAE,WAAoB,EAAmB,EAAE;IACnF,MAAM,MAAM,GAAG,IAAI,QAAQ,EAAE,CAAC;IAC9B,MAAM,MAAM,GAAG,WAAW,KAAK,SAAS,CAAC,CAAC,CAAC,EAAE,WAAW,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC;IAChE,MAAM,QAAQ,GAAG,MAAM,MAAM,CAAC,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;IAClD,OAAO,QAAQ,CAAC,OAAO,CAAC;AAC1B,CAAC,CAAC","sourcesContent":["import OpenAI from \"openai\";\nimport { CONFIG } from \"../config.js\";\nimport { createLogger, format, transports } from \"winston\";\n\n/**\n * Configuration options for the AI client\n */\ninterface AIClientConfig {\n  /** OpenAI model to use (default: gpt-4) */\n  model?: string;\n  /** Temperature for response randomness (default: 0.7) */\n  temperature?: number;\n  /** Maximum retry attempts (default: 3) */\n  maxRetries?: number;\n  /** Base delay between retries in ms (default: 1000) */\n  retryDelay?: number;\n  /** Custom system prompt override */\n  systemPrompt?: string;\n  /** Timeout for API calls in ms (default: 30000) */\n  timeout?: number;\n}\n\n/**\n * Response from the AI service\n */\ninterface AIResponse {\n  /** Generated content */\n  content: string;\n  /** Token usage statistics */\n  usage?: {\n    promptTokens: number;\n    completionTokens: number;\n    totalTokens: number;\n  };\n  /** Generation metadata */\n  metadata: {\n    /** Generation timestamp */\n    timestamp: string;\n    /** Model used */\n    model: string;\n    /** Time taken in ms */\n    duration: number;\n    /** Number of retries needed */\n    retries: number;\n  };\n}\n\n// Configure logger\nconst logger = createLogger({\n  format: format.combine(\n    format.timestamp(),\n    format.json()\n  ),\n  transports: [\n    new transports.Console(),\n    new transports.File({ filename: 'error.log', level: 'error' }),\n    new transports.File({ filename: 'ai-client.log' })\n  ]\n});\n\n/**\n * Custom error for AI-related failures\n */\nexport class AIError extends Error {\n  constructor(message: string, public readonly details?: unknown) {\n    super(message);\n    this.name = \"AIError\";\n  }\n}\n\n/**\n * AIClient class for interacting with OpenAI's API\n */\nexport class AIClient {\n  private readonly openai: OpenAI;\n  private readonly config: Required<AIClientConfig>;\n\n  /**\n   * Creates a new AIClient instance\n   * @param apiKey OpenAI API key\n   * @param config Optional configuration overrides\n   * @throws {AIError} If API key is missing or invalid\n   */\n  constructor(\n    apiKey: string = CONFIG.OPENAI_API_KEY,\n    config: AIClientConfig = {}\n  ) {\n    if (!apiKey?.trim()) {\n      throw new AIError(\"OpenAI API key is required\");\n    }\n\n    this.openai = new OpenAI({ apiKey });\n    this.config = {\n      model: config.model || \"gpt-4\",\n      temperature: config.temperature ?? 0.7,\n      maxRetries: config.maxRetries ?? 3,\n      retryDelay: config.retryDelay ?? 1000,\n      systemPrompt: config.systemPrompt ?? this.getDefaultSystemPrompt(),\n      timeout: config.timeout ?? 30000\n    };\n\n    logger.info(\"AIClient initialized\", {\n      model: this.config.model,\n      temperature: this.config.temperature\n    });\n  }\n\n  private getDefaultSystemPrompt(): string {\n    return `You are an expert AI assistant specialized in software testing and automation.\nGenerate high-quality, maintainable test code following these best practices:\n\nTest Design:\n- Follow Arrange-Act-Assert pattern\n- Keep tests focused and single-purpose\n- Use meaningful, descriptive test names\n- Include proper setup/teardown\n- Ensure test isolation\n\nCode Quality:\n- Implement proper error handling\n- Add descriptive assertion messages\n- Follow TypeScript best practices\n- Keep code DRY and maintainable\n- Add JSDoc documentation\n\nTest Stability:\n- Handle timeouts and retries\n- Add proper waits and assertions\n- Avoid flaky selectors\n- Consider edge cases\n- Implement proper logging\n\nPerformance:\n- Optimize test execution\n- Avoid unnecessary waits\n- Reuse browser contexts when possible\n- Implement parallel execution\n- Consider resource cleanup`;\n  }\n\n  /**\n   * Send a prompt to the AI and get a response with retries\n   * @param prompt The user's prompt\n   * @param config Optional per-request configuration\n   * @returns Promise with the AI's response\n   * @throws {AIError} If API call fails after all retries\n   */\n  async ask(prompt: string, config: Partial<AIClientConfig> = {}): Promise<AIResponse> {\n    const startTime = Date.now();\n    let retryCount = 0;\n\n    try {\n      if (!prompt?.trim()) {\n        throw new AIError(\"Prompt cannot be empty\");\n      }\n\n      const effectiveConfig = { ...this.config, ...config };\n      let lastError: Error | null = null;\n\n      for (let attempt = 1; attempt <= effectiveConfig.maxRetries; attempt++) {\n        try {\n          const completion = await Promise.race([\n            this.openai.chat.completions.create({\n              model: effectiveConfig.model,\n              messages: [\n                {\n                  role: \"system\",\n                  content: effectiveConfig.systemPrompt\n                },\n                { role: \"user\", content: prompt }\n              ],\n              temperature: effectiveConfig.temperature,\n              max_tokens: 2000,\n              presence_penalty: 0.1,\n              frequency_penalty: 0.1\n            }),\n            new Promise((_, reject) => setTimeout(() => reject(new AIError(\"Request timeout\")), effectiveConfig.timeout))\n          ]) as OpenAI.Chat.ChatCompletion;\n\n          const content = completion.choices[0]?.message?.content;\n          if (!content?.trim()) {\n            throw new AIError(\"Empty response from OpenAI\");\n          }\n\n          const duration = Date.now() - startTime;\n          logger.info(\"AI response generated\", {\n            duration,\n            model: effectiveConfig.model,\n            tokens: completion.usage?.total_tokens\n          });\n\n          return {\n            content,\n            usage: completion.usage ? {\n              promptTokens: completion.usage.prompt_tokens,\n              completionTokens: completion.usage.completion_tokens,\n              totalTokens: completion.usage.total_tokens\n            } : undefined,\n            metadata: {\n              timestamp: new Date().toISOString(),\n              model: effectiveConfig.model,\n              duration,\n              retries: retryCount\n            }\n          };\n        } catch (error) {\n          retryCount++;\n          lastError = error instanceof Error ? error : new Error(String(error));\n          logger.warn(`Attempt ${attempt} failed`, {\n            error: lastError.message,\n            attempt,\n            retryCount\n          });\n\n          if (attempt < effectiveConfig.maxRetries) {\n            const delay = effectiveConfig.retryDelay * Math.pow(2, attempt - 1);\n            await this.sleep(delay); // Exponential backoff\n            continue;\n          }\n        }\n      }\n\n      throw new AIError(\n        `Failed after ${effectiveConfig.maxRetries} attempts`,\n        lastError?.message\n      );\n    } catch (error) {\n      const finalError = error instanceof Error ? error : new Error(String(error));\n      logger.error(\"AI request failed\", {\n        error: finalError.message,\n        duration: Date.now() - startTime,\n        retries: retryCount\n      });\n      throw new AIError(finalError.message, {\n        duration: Date.now() - startTime,\n        retries: retryCount\n      });\n    }\n  }\n\n  private sleep(ms: number): Promise<void> {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n}\n\n/**\n * Simplified function for generating AI responses\n * @param prompt The prompt to send to the AI\n * @param temperature Optional temperature override\n * @returns Promise with the generated content\n */\nexport const askAI = async (prompt: string, temperature?: number): Promise<string> => {\n  const client = new AIClient();\n  const config = temperature !== undefined ? { temperature } : {};\n  const response = await client.ask(prompt, config);\n  return response.content;\n};\n"]}